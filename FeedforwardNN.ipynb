{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# FeedForward Tutorial\n",
    "---\n",
    "A feedforward neural network is an artificial neural network wherein connections between the nodes do not form a cycle. As such, it is different from recurrent neural networks. It is illustrated in the following figure\n",
    "![title](img/feed_forward.png)\n",
    "\n",
    "The feedforward neural network was the first and simplest type of artificial neural network devised. In this network, the information moves in only one direction, forward, from the input nodes, through the hidden nodes (if any) and activation funtion to the output nodes. There are no cycles or loops in the network.\n",
    "\n",
    "![title](img/single.png)\n",
    "The simplest kind of neural network is a single-layer perceptron network, which consists of a single layer of output nodes; the inputs are fed directly to the outputs via a series of weights. In this way it can be considered the simplest kind of feed-forward network. The sum of the products of the weights and the inputs is calculated in each node, and if the value is above some threshold (typically 0) the neuron fires and takes the activated value (typically 1); otherwise it takes the deactivated value (typically -1). \n",
    "\n",
    "### What is Activation Function ?\n",
    "You could have a question about activation function. Itâ€™s just a thing (node) that you add to the output end of any neural network. It is also known as **Transfer Function**. It can also be attached in between two Neural Networks.It is used to determine the output of neural network like yes or no. It maps the resulting values in between 0 to 1 (sigmoid) whatever the inputs are.\n",
    "![title](img/sigmoid.png)\n",
    "\n",
    "### Single-layer perceptron network : \n",
    "It can only solve linear problems such as AND problem and OR problem (see the following figure)\n",
    "![title](img/linear.png)\n",
    "\n",
    "However, it cannot solve XOR problem due to it is a non-linear problem. We could not use a single line to split it to two parts.(see the following figure)\n",
    "![title](img/nonlinear.png)\n",
    "If we use two and more layers of neural network, it colud solve the problem with two decision boundaries like the following figure.**Each \"Decision Boundary\" line represents one layer** in our MLP.\n",
    "![title](img/two-layer.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Plan to code a feedforward Pass\n",
    "---\n",
    "How can we do the forward pass by code ? We take a look the following figure : \n",
    "<img src=\"img/feedforward.png\" alt=\"drawing\" width=\"500px\"/>\n",
    "\n",
    "If our input $X=\\{x_0,x_1,...,x_n\\}$,each output value $o_j$ can be calculate by :\n",
    "\n",
    "### $o_j = \\sigma[{\\sum^{n}_{i=0}{W_{ij}x_{j}+b_{j}}}]$\n",
    "where $W\\in R^{ i x j}$, $b\\in R^{ j}$ and $\\sigma$ is activation function. The formula can be implement by ** two multiplied matrices ** and ** plus a bias vector ** like this:\n",
    "![title](img/mutipled_matrix.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Start to code a feedforward pass\n",
    "---\n",
    "### First we need to import packages and defined some variable for later work\n",
    "* numpy\n",
    "\n",
    "### We need the variables in the following list :\n",
    "* weights \n",
    "* bias\n",
    "* number of layers\n",
    "* update_weight (backward)\n",
    "* update_bias (backward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1)  # Seed the random number generator, we can reproduce our results deterministically\n",
    "weights = {}  # weights\n",
    "biases = {} # bias\n",
    "num_layers = 1  # Set initial number of layer to one (input layer)\n",
    "adjustments_w = {}  # adjustements\n",
    "adjustments_b = {}  # adjustements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    global num_layers\n",
    "    global weights\n",
    "    global biases\n",
    "    global adjustments_w\n",
    "    global adjustments_b\n",
    "    weights = {}  # weights\n",
    "    biases = {} # bias\n",
    "    num_layers = 1  # Set initial number of layer to one (input layer)\n",
    "    adjustments_w = {}  # adjustements\n",
    "    adjustments_b = {}  # adjustements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define a add_layer function that can add layer in the network\n",
    "---\n",
    "#### When a layer was build, we must initial layer's variables:\n",
    "* weights $W_{m \\times n}$: random value in range [-1,1] \n",
    "* bias $b_{n}$ : random value in range [-1,1]  \n",
    "* update_weight $\\Delta W_{m \\times n}$: 0 \n",
    "* update_bias $\\Delta b_{n}$ : 0 \n",
    "\n",
    "#### Then, you should add the number of layers to record how many layers we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_layer(shape):\n",
    "    global num_layers\n",
    "    global weights\n",
    "    global biases\n",
    "    global adjustments_w\n",
    "    global adjustments_b\n",
    "    \n",
    "    # inital weights in range(-1,1) \n",
    "    weights[num_layers] = 2 * np.random.random(shape) - 1\n",
    "    # inital bias in range(-1,1)\n",
    "    biases[num_layers] = 2 * np.random.random((1,shape[1])) - 1\n",
    "    # inital adjustements i\n",
    "    adjustments_w[num_layers] = np.zeros(shape)\n",
    "    adjustments_b[num_layers] = np.zeros((1,shape[1]))\n",
    "    # plus num_layer \n",
    "    num_layers += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define activation functions \n",
    "---\n",
    "### In the feedforward neural network, we should use two activation function:\n",
    "* sigmoid : It is used to calculate the value in feedfoward.\n",
    "    \n",
    "### $ \\sigma(x) = \\frac{1}{1 + e^{-x}} $\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define forward_propagate function\n",
    "---\n",
    "In this function, we need to caculate each layer output. According to the plan we have mentioned above, the outputs are got by ** mutlipling a vector of inputs and a matrix of weights**, then **plus a bias vector**. Final, we use **activation function (sigmoid)** to map the outputs into the range[0,1]. Ater that, we will finish the step of forward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def forward_propagate(data):       \n",
    "    global num_layers\n",
    "    global weights\n",
    "    global biases\n",
    "    # Progapagate through network and hold values for use in back-propagation\n",
    "    activation_values = {}\n",
    "    activation_values[1] = data\n",
    "\n",
    "    for layer in range(2,num_layers+1):\n",
    "        # y = data.T (batch_size, input_size) * weight(input_size, output_size) + bias(output_size)    \n",
    "        data = np.dot(data.T, weights[layer-1])+ biases[layer-1]\n",
    "        # a = f(y)\n",
    "        data = sigmoid(data).T\n",
    "        activation_values[layer] = data\n",
    "        \n",
    "    return activation_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan to code a backward Pass\n",
    "---\n",
    "How did we set our weights in forward pass ? We must define a **loss function** to decide what weights can decrease difference of outputs and label. To find the minimum value of loss by given weights, we must use **gradient descent** algorithm to optimize. **Gradient descent** is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model. Parameters refer to coefficients in Linear Regression and weights in neural networks.\n",
    "\n",
    "\n",
    "To caculate each layer's update_weight and update_bias, we must partial differentiate the loss function with our parameters.You can watch [the video](https://www.youtube.com/watch?v=ibJpTrp5mcE) which introduces how can we optimize our parameters from loss function by backward pass. The following equactions show how can we get **update_weights** and **update_bias** by **chain rule**. \n",
    "\n",
    "update_weight $\\Delta w $ = $\\frac{\\partial L}{\\partial w} $= $\\frac{\\partial L}{\\partial {y}}\\frac{\\partial {y}}{\\partial w} $\n",
    "\n",
    "update_bias $\\Delta b $ = $\\frac{\\partial L}{\\partial b} $= $\\frac{\\partial L}{\\partial {y}}\\frac{\\partial {y}}{\\partial b} $\n",
    "\n",
    "#### weight\n",
    "$\\frac{\\partial y}{\\partial w} =\\frac{\\partial (Wx + b)}{\\partial y}$  =  $x$\n",
    "\n",
    "#### bias ( just different with weight in this part )\n",
    "$\\frac{\\partial b}{\\partial w} =\\frac{\\partial (Wx + b)}{\\partial b}$ =  $1$ \n",
    "\n",
    "---\n",
    "$\\frac{\\partial L}{\\partial y} =\\frac{\\partial a}{\\partial y} \\frac{\\partial L}{\\partial a} $\n",
    "\n",
    "$\\frac{\\partial a}{\\partial y} =\\frac{\\partial \\sigma(y)}{\\partial y} = $   $\\sigma^{'}(y)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### if layer is output layer :\n",
    "\n",
    "$\\frac{\\partial L}{\\partial y} = \\sigma^{'}(y) \\frac{\\partial L}{\\partial a} = \\sigma^{'}(y) \\frac{\\partial (y \\log(a) + (1-y)\\log(1-a))}{\\partial a} =  \\sigma^{'}(y) \\times (a-y)$\n",
    "\n",
    "\n",
    "#### if layer is hidden layer :\n",
    "\n",
    "$\\frac{\\partial L}{\\partial y} = \\sigma^{'}(y) \\frac{\\partial L}{\\partial a} $ \n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a} = \\frac{\\partial y_{n+1}}{\\partial a}\\frac{\\partial L}{\\partial y_{n+1}} = w \\times \\frac{\\partial L}{\\partial y_{n+1}} $\n",
    "\n",
    "($\\frac{\\partial L}{\\partial y_{n+1}}$has been computed at last iteration )\n",
    "\n",
    "## Start to code a backward pass\n",
    "---\n",
    "## Define loss function\n",
    "For our XOR problem,a classification task, we consider the inputs and decide its output is **\"True\"** or **False**. Therefore, we take cross entropy as our loss function. The loss function is defined by :\n",
    "\n",
    "<img src=\"img/loss.png\" alt=\"drawing\" width=\"300px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_func(outputs, targets):\n",
    "    # cross_entropy \n",
    "    return np.mean(-np.sum(targets * np.log(outputs) + (1- targets) * np.log(1-outputs), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the derivative of sigmoid function\n",
    "---\n",
    "It is used to calculate the gradient in backward pass.\n",
    "$ \\frac{d\\sigma(x)}{d(x)}$</span> = $\\sigma(x) \\times (1-\\sigma(x)) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# derivative of sigmoid  \n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define back_propagate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def back_propagate(outputs, targets):\n",
    "    global num_layers\n",
    "    global weights\n",
    "    global biases\n",
    "    global adjustments_w\n",
    "    global adjustments_b\n",
    "    \n",
    "    deltas = {}\n",
    "\n",
    "    # Delta of output Layer ( cross_entropy derivative is (output-target))\n",
    "    # L/y = sigmoid_derivative * (loss_func_derivative)\n",
    "    deltas[num_layers] = sigmoid_derivative(outputs[num_layers])*(outputs[num_layers] - targets)\n",
    "   \n",
    "    # Delta of hidden Layers\n",
    "    # L/y = sigmoid_derivative * (weight * last L/y)  \n",
    "    for layer in reversed(range(2, num_layers)):  # All layers except input/output\n",
    "        a_val = outputs[layer]\n",
    "        weight = weights[layer]\n",
    "        bias = biases[layer]\n",
    "        prev_deltas = deltas[layer+1]\n",
    "\n",
    "        deltas[layer] = np.multiply(np.dot(weight, prev_deltas), sigmoid_derivative(a_val))\n",
    " \n",
    "\n",
    "    # Caclculate total adjustements based on deltas\n",
    "    # update_weight = L/y * x\n",
    "    # update_bais = L/y * 1\n",
    "    for layer in range(1, num_layers):\n",
    "        adjustments_w[layer] += np.dot(deltas[layer+1],outputs[layer].T).T\n",
    "        adjustments_b[layer] += np.dot(deltas[layer+1],1).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define gradient_descent function\n",
    "---\n",
    "$ w_{new} = w - \\eta \\Delta{w} $ \n",
    "\n",
    "\n",
    "$ b_{new} = b - \\eta \\Delta{b} $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(batch_size, learning_rate):\n",
    "    global num_layers\n",
    "    global weights\n",
    "    global biases\n",
    "    global adjustments_w\n",
    "    global adjustments_b\n",
    "    \n",
    "    # Calculate partial derivative and take a step in that direction\n",
    "    for layer in range(1, num_layers):\n",
    "\n",
    "        partial_w = (1/batch_size) * adjustments_w[layer]\n",
    "        partial_b = (1/batch_size) * adjustments_b[layer]\n",
    "\n",
    "\n",
    "        weights[layer] += learning_rate * -partial_w\n",
    "        biases[layer] += learning_rate * -partial_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define train function\n",
    "---\n",
    "#### Order of train :\n",
    "    1. forward_prop\n",
    "    2. caculate loss\n",
    "    3. back_prop\n",
    "    4. gradient_descent\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(inputs, targets, num_epochs, learning_rate=0.01, stop_loss=1e-5):\n",
    "    global num_layers\n",
    "    error = []\n",
    "\n",
    "    for iteration in range(num_epochs):\n",
    "        loss = 0\n",
    "        for i in range(len(inputs)):\n",
    "            x = inputs[i]\n",
    "            y = targets[i]\n",
    "            \n",
    "            # Pass the training set through our neural network\n",
    "            output = forward_propagate(x)\n",
    "\n",
    "            # Calculate the error\n",
    "            loss += loss_func(output[num_layers], y)\n",
    "            \n",
    "            # Calculate Adjustements\n",
    "            back_propagate(output, y)\n",
    "\n",
    "        gradient_descent(i, learning_rate)\n",
    "        error.append(loss/len(inputs))\n",
    "        # Check if loss criterion is satisfied\n",
    "        if np.mean(error[-(i+1):]) < stop_loss and iteration > 0:\n",
    "            break\n",
    "\n",
    "    #show the loss curve\n",
    "    plt.plot(range(len(error)), error)\n",
    "    plt.show()\n",
    "\n",
    "    return(np.asarray(error), iteration+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define predict function\n",
    "---\n",
    "We must have a function to map value to True and False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    global num_layers\n",
    "    global weights\n",
    "    global biases\n",
    "\n",
    "    # pass data through pre-trained network\n",
    "    for layer in range(1,num_layers):\n",
    "        # h = data (batch_size, input_size) * weight(input_size, output_size) + bias(output_size) \n",
    "        data = np.dot(data, weights[layer]) + biases[layer]\n",
    "        # a = f(h)\n",
    "        data = sigmoid(data)\n",
    "        \n",
    "    data = data > 0.5\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## AND Dataset\n",
    "---\n",
    "Our first dataset is AND problem. The AND gate have to let all inputs are true and its output will be true. The following figure is AND truth table\n",
    "![title](img/AND_truth_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f771b7a7320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error =  3.32089277585e-05\n",
      "Epoches needed to train =  1000\n",
      "data [0 0], value [False]\n",
      "data [0 1], value [False]\n",
      "data [1 0], value [False]\n",
      "data [1 1], value [ True]\n"
     ]
    }
   ],
   "source": [
    "# Add Layers (Input layer is created by default)\n",
    "init()\n",
    "add_layer((2, 1))\n",
    "\n",
    "# AND function\n",
    "training_data = np.asarray([[0, 0], [0, 1], [1, 0], [1, 1]]).reshape(4, 2, 1)\n",
    "training_labels = np.asarray([[0], [0], [0], [1]])\n",
    "\n",
    "error, iteration = train(training_data, training_labels, 1000)\n",
    "print('Error = ', np.mean(error[-4:]))\n",
    "print('Epoches needed to train = ', iteration)\n",
    "\n",
    "training_data = np.asarray([[0, 0], [0, 1], [1, 0], [1, 1]]).reshape(4, 2)\n",
    "label = predict(training_data)\n",
    "\n",
    "for i in range(4):\n",
    "    print(\"data {}, value {}\".format(training_data[i],label[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## XOR Dataset\n",
    "---\n",
    "Our second dataset is XOR problem. The XOR gate is a digital logic gate that gives a true (1 or HIGH) output when the number of true inputs is odd.\n",
    "![title](img/XOR_truth_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f771b79d240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error =  2.74960197114\n",
      "Epoches needed to train =  1000\n",
      "data [0 0], value [False]\n",
      "data [0 1], value [ True]\n",
      "data [1 0], value [ True]\n",
      "data [1 1], value [ True]\n"
     ]
    }
   ],
   "source": [
    "# Add Layers (Input layer is created by default)\n",
    "init()\n",
    "add_layer((2, 1))\n",
    "\n",
    "# XOR function\n",
    "training_data = np.asarray([[0, 0], [0, 1], [1, 0], [1, 1]]).reshape(4, 2, 1)\n",
    "training_labels = np.asarray([[0], [1], [1], [0]])\n",
    "\n",
    "error, iteration = train(training_data, training_labels, 1000)\n",
    "print('Error = ', np.mean(error[-4:]))\n",
    "print('Epoches needed to train = ', iteration)\n",
    "\n",
    "training_data = np.asarray([[0, 0], [0, 1], [1, 0], [1, 1]]).reshape(4, 2)\n",
    "label = predict(training_data)\n",
    "\n",
    "for i in range(4):\n",
    "    print(\"data {}, value {}\".format(training_data[i],label[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can't predict correct value in XOR problem in single layer because XOR is non-linear problem. Therefore, we add one more layer to enhance our network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIZW7iIgP/X+ujax/NlTaxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f771b79d898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error =  0.0512476351996\n",
      "Epoches needed to train =  1000\n",
      "data [0 0], value [False]\n",
      "data [0 1], value [ True]\n",
      "data [1 0], value [ True]\n",
      "data [1 1], value [False]\n"
     ]
    }
   ],
   "source": [
    "# Add Layers (Input layer is created by default)\n",
    "init()\n",
    "add_layer((2, 4))\n",
    "add_layer((4, 1))\n",
    "\n",
    "# XOR function\n",
    "training_data = np.asarray([[0, 0], [0, 1], [1, 0], [1, 1]]).reshape(4, 2, 1)\n",
    "training_labels = np.asarray([[0], [1], [1], [0]])\n",
    "\n",
    "error, iteration = train(training_data, training_labels, 1000)\n",
    "print('Error = ', np.mean(error[-4:]))\n",
    "print('Epoches needed to train = ', iteration)\n",
    "\n",
    "training_data = np.asarray([[0, 0], [0, 1], [1, 0], [1, 1]]).reshape(4, 2)\n",
    "label = predict(training_data)\n",
    "\n",
    "for i in range(4):\n",
    "    print(\"data {}, value {}\".format(training_data[i],label[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Reference \n",
    "---\n",
    "Feedforward in Wiki : https://en.wikipedia.org/wiki/Feedforward\n",
    "<br>\n",
    "CS231n : http://cs231n.github.io/optimization-2/\n",
    "<br>\n",
    "Feedforward Neural Networks in BRILLIANT :https://brilliant.org/wiki/feedforward-neural-networks/\n",
    "<br>\n",
    "æŽå®æ¯… backpropgation æ•™å­¸è¦–é » : https://www.youtube.com/watch?v=ibJpTrp5mcE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
